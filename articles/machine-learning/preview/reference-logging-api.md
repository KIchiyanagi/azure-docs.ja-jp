---
title: "Azure ML ロギング API リファレンス | Microsoft Docs"
description: "ロギング API リファレンス。"
services: machine-learning
author: akshaya-a
ms.author: akannava
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.topic: article
ms.date: 09/25/2017
ms.openlocfilehash: 1906425c6657fb6232a9dc306b05f9171c9c7bef
ms.sourcegitcommit: 6699c77dcbd5f8a1a2f21fba3d0a0005ac9ed6b7
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/11/2017
---
# <a name="logging-api-reference"></a>ロギング API リファレンス

Azure ML ロギング ライブラリでは、履歴サービスによって追跡されるメトリックとファイルをプログラムで出力し、後で分析することができます。 現時点では、いくつかの基本的な種類のメトリックとファイルがサポートされていますが、Python パッケージの将来のリリースにより、サポートされる種類のセットは増加します。

## <a name="uploading-metrics"></a>メトリックのアップロード

```python
# import logging API package
from azureml.logging import get_azureml_logger

# initialize a logger object
logger = get_azureml_logger()

# log "scalar" metrics
logger.log("simple integer value", 7)
logger.log("simple float value", 3.141592)
logger.log("simple string value", "this is a string metric")

# log a list of numerical values. 
# this automatically creates a chart in the Run History details page
logger.log("chart data points", [1, 3, 5, 10, 6, 4])
```

既定では、すべてのメトリックは、送信でプログラムの実行が妨げられないように、非同期的に送信されます。 そのため、エッジ ケースで複数のメトリックが送信されると、順序の問題が発生する可能性があります。 その例としては、2 つのメトリックが同時にログに記録されたが、何らかの理由で、ユーザーがその正確な順序を保持したい場合があります。 他にも、短時間でエラーになる可能性のあることが知られているいくつかのコードを実行する前にメトリックを追跡する必要があるようなケースが挙げられます。 どちらの場合の解決策も、メトリックがログに完全に記録されるまで "_待機_" してから続行することです。

```python
# blocking call
logger.log("my metric 1", 1).wait()
logger.log("my metric 2", 2).wait()
```

## <a name="consuming-metrics"></a>メトリックの使用

メトリックは、履歴サービスによって格納され、そのメトリックを生成した実行に関連付けられます。 [実行履歴] タブと以下の CLI コマンドの両方を使用すると、実行が完了した後にメトリック (および以下のアーティファクト) を取得できます。

```azurecli
# show the last run
$ az ml history last

# list all past runs
$ az ml history list 

# show a paritcular run
$ az ml history info -r <runid>
```

## <a name="artifacts-files"></a>アーティファクト (ファイル)

AzureML では、メトリックだけでなく、ファイルも追跡することができます。 既定では、プログラムの作業ディレクトリ (コンピューティング コンテキストにおけるプロジェクト フォルダー) に関連する `outputs` フォルダーに書き込まれるすべてのファイルが履歴サービスにアップロードされ、後で分析できるように追跡されます。 注意事項は、各ファイルのサイズを 512 MB 未満にする必要があることです。


```Python
# Log content as an artifact
logger.upload("artifact/path", "This should be the contents of artifact/path in the service")
```

## <a name="consuming-artifacts"></a>アーティファクトの使用

追跡対象のアーティファクトの内容を出力するには、ユーザーは指定した実行の [実行履歴] タブを使用して、アーティファクトを**ダウンロード**または**昇格**するか、以下の CLI コマンドを使用して同じ結果を得ることができます。

```azurecli
# show all artifacts generated by a run
$ az ml history info -r <runid> -a <artifact/path>

# promote a particular artifact
$ az ml history promote -r <runid> -ap <artifact/prefix> -n <name of asset to create>
```
## <a name="next-steps"></a>次のステップ
- [あやめの分類のチュートリアルのパート 2](tutorial-classifying-iris-part-2.md) を順を追って参照し、動作中のロギング API を確認します。
- [Azure Machine Learning Workbench で実行履歴とモデルのメトリックを使用する方法](how-to-use-run-history-model-metrics.md)を確認して、ロギング API を実行履歴で使用する方法について理解を深めます。
