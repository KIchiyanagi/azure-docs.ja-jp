---
title: "Azure Machine Learning プレビュー機能の概念の概要 | Microsoft Docs"
description: "サブスクリプション、アカウント、ワークスペース、プロジェクトなど、Azure Machine Learning のプレビュー機能の概念の概要。"
services: machine-learning
author: serinakaye
ms.author: serinak
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.topic: article
ms.date: 09/06/2017
ms.openlocfilehash: 3d4ba2ca6f7adc8b51030c02d9e9eeb2b9995bb4
ms.sourcegitcommit: 6699c77dcbd5f8a1a2f21fba3d0a0005ac9ed6b7
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/11/2017
---
# <a name="azure-machine-learning---concepts"></a>Azure Machine Learning - 概念

この記事は、Azure Machine Learning を使用するために知っておく必要のある概念を定義し、説明します。 

![概念の階層](media/overview-general-concepts/hierarchy.png)

- **サブスクリプション:** Azure サブスクリプションを持っていると、Azure リソースへのアクセスが許可されます。 Azure Machine Learning は、コンピューティング、ストレージ、他の多くの Azure リソースおよびサービスと深く連携しているので、Workbench を使用するには、各ユーザーが有効な Azure サブスクリプションへのアクセス権を持っている必要があります。 ユーザーがリソースを作成するには、そのサブスクリプション内で十分なアクセス許可も持っている必要があります。


- **実験アカウント:** 実験アカウントとは、Azure ML と課金手段で必要とされる Azure リソースです。 これには、自分のワークスペースが含まれます。また、ワークスペースにはプロジェクトが含まれます。 実験アカウントには、_seats_ と呼ばれる複数のユーザーを追加することができます。 Azure ML Workbench を使用して実験を実行するには、実験アカウントへのアクセス権を持っている必要があります。 


- **モデル管理アカウント:** モデル管理アカウントも、モデルを管理するために Azure ML で必要とされる Azure リソースです。 これを使用して、モデルとマニフェストの登録、コンテナー化された Web サービスの構築、ローカルまたはクラウドでのデプロイを実行することができます。 これは、Azure ML のもう 1 つの課金手段でもあります。


- **ワークスペース:** ワークスペースとは、Azure ML で共有とコラボレーションを行うための主要なコンポーネントです。 プロジェクトは、ワークスペース内でグループ化されます。 ワークスペースは、実験アカウントに追加された複数のユーザーと共有できます。


- **プロジェクト:** Azure Machine Learning では、プロジェクトは、問題を解決するために実行されているすべての作業の論理コンテナーです。 プロジェクトはローカル ディスク上の 1 つのファイル フォルダーにマップされ、ファイルやサブ フォルダーを追加することができます。 プロジェクトは、ソース管理とコラボレーションのために、オプションで Git リポジトリに関連付けることができます。  

- **実験:** Azure ML では、実験は 1 つのエントリ ポイントから実行できる 1 つまたは複数のソース コード ファイルです。 データ インジェスト、特徴エンジニアリング、モデルのトレーニング、モデルの評価などのタスクが含まれます。 Azure ML は、現時点では Python または PySpark の実験のみをサポートしています。


- **モデル:** Azure Machine Learning では、モデルとは、機械学習の実験の産物です。 データに正しく適用されたときに予測値が生成されるレシピです。 モデルは、テスト環境または運用環境にデプロイして、新しいデータのスコア付けにご利用いただけます。 モデルを運用環境にデプロイすると、パフォーマンスとデータの誤差を監視し、必要に応じて再トレーニングすることができます。 

- **コンピューティング ターゲット:** コンピューティング ターゲットとは、実験を実行するために構成するコンピューティング リソースです。 ローカル コンピューター (Windows または macOS)、ローカル コンピューターまたは Azure 上の Linux VM で実行されている Docker コンテナー、HDInsight Spark クラスターを指定できます。


- **実行:** 実験サービスでは、実行をコンピューティング ターゲットでの実験の実行の有効期間として定義します。 Azure ML は、各実行の情報を自動的にキャプチャし、実行履歴の形式で個々の実験の履歴全体を表示します。

- **環境:** Azure Machine Learning では、環境は、モデルのデプロイおよび管理に使用される個々のコンピューティング リソースを示しています。 コンテキストと構成に応じて、ローカル コンピューター、Azure 上の Linux VM、Azure Container Service で実行されている Kubernetes クラスターを指定できます。 モデルは、これらの環境で実行されている Docker コンテナーでホストされ、REST API エンドポイントとして公開されます。


- **管理モデル:** モデル管理により、Web サービスとしてモデルをデプロイし、さまざまなバージョンのモデルを管理し、パフォーマンスとメトリックを監視することができます。 管理モデルは、Azure Machine Learning モデル管理アカウントに登録されます。

- **マニフェスト:** モデル管理システムによってモデルが運用環境にデプロイされると、そのモデルには、モデル、依存関係、スコア付けのスクリプト、サンプル データ、およびスキーマを網羅できるマニフェストが含まれます。 マニフェストは、Docker コンテナー イメージを作成するために使用されるレシピです。 モデル管理を使用して、マニフェストを自動生成し、別のバージョンを作成して、これらのマニフェストを管理することができます。 


- **イメージ:** マニフェストを使用して、Docker イメージを生成 (および再生成) することができます。 コンテナー化された Docker イメージは、クラウド、ローカル マシン、または IoT デバイス上で柔軟に実行できます。 イメージは、自己完結型であり、モデルで新しいデータをスコア付けするために必要なすべての依存関係が含まれます。 

- **サービス:** モデル管理により、モデルを Web サービスとしてデプロイすることができます。 Web サービスのロジックと依存関係は、イメージにカプセル化されます。 各 Web サービスは、所定の URL へのサービス要求に対応する準備が整った、イメージに基づくコンテナーのセットです。 Web サービスは、単一のデプロイとしてカウントされます。
